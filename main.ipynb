{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. ~~Code up VAE~~\n",
    "2. ~~Code up M (RNN)~~\n",
    "3. Code up Train Loop for M\n",
    "3. Code up C (Controller)\n",
    "4. Set up Car Racing\n",
    "5. Set up Doom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "import time\n",
    "from torch import optim\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "    sys.argv = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--weights_file\",type=str,default=\"None\")\n",
    "parser.add_argument(\"--lr\",type=float, default=0.0001)\n",
    "parser.add_argument(\"--ctl_type\",type=str, default=\"lstm\")\n",
    "parser.add_argument(\"--opt\",type=str, default=\"adam\")\n",
    "parser.add_argument(\"--iters\",type=int, default=100000)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    display(display_animation(anim, default_mode='loop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(bs=128,nb=1):\n",
    "    for _ in range(nb):\n",
    "        x = Variable(torch.Tensor(bs,3,64,64).uniform_(-1,1)).cuda()\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim(name,  model, lr, momentum):\n",
    "    if name == \"adam\":\n",
    "        return optim.Adam(params=model.parameters(),\n",
    "                        lr=lr)\n",
    "    elif name == \"sgd\":\n",
    "        return optim.SGD(params=model.parameters(),\n",
    "                        lr=lr,\n",
    "                        momentum=momentum)\n",
    "    elif name == \"rmsprop\":\n",
    "          return optim.RMSprop(params=model.parameters(),\n",
    "                        lr=lr,\n",
    "                        momentum=momentum)\n",
    "\n",
    "def print_info(mode,loss,t0,it):\n",
    "    print(\"time: %8.4f\"% (time.time() - t0))\n",
    "    print(\"%s Loss for it %i: %8.4f\"%(mode.capitalize(),it,loss))\n",
    "    #print(\"%s Accuracy for epoch %i: %8.4f\"%(mode.capitalize(),epoch,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(mode, model,opt,epoch):\n",
    "    criterion = vae_loss\n",
    "    dataloader = data_gen()\n",
    "    if mode == \"train\":\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    it_losses = []\n",
    "    for it, xv in enumerate(dataloader):\n",
    "\n",
    "        if mode == \"train\":\n",
    "            opt.zero_grad()\n",
    "        xh,mu,sigma = model(xv)\n",
    "\n",
    "        loss = criterion(xv,xh,mu,sigma)\n",
    "\n",
    "        it_losses.append(loss.data[0])\n",
    "        if mode == \"train\":\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "    loss = np.mean(it_losses)\n",
    "    #writer.add_scalar(\"%s/loss\"%mode,scalar_value=loss,global_step=epoch)\n",
    "    return loss\n",
    "\n",
    "def train(\n",
    "            model,\n",
    "            lr=0.1,\n",
    "            momentum=0.9,\n",
    "            test=False,\n",
    "            val=True,\n",
    "            verbose=True,\n",
    "            num_epochs=5, optimizer=\"adam\"):\n",
    "    \n",
    "        if test:\n",
    "            modes = [\"test\"]\n",
    "            num_epochs = 1\n",
    "            if args.weights_file == \"None\":\n",
    "                assert False, \"I don't think you meant to run on the test set without a weights file!\"\n",
    "        else:\n",
    "            modes = [\"train\"]\n",
    "            if val:\n",
    "                modes.append(\"val\")\n",
    "        \n",
    "        if args.weights_file != \"None\":\n",
    "            model.load_state_dict(torch.load(args.weights_file))\n",
    "\n",
    "\n",
    "        model = model.cuda()\n",
    "        opt = get_optim(optimizer,model,lr,momentum)\n",
    "        for epoch in range(num_epochs):\n",
    "            for mode in modes:\n",
    "                t0 = time.time()\n",
    "                loss = do_epoch(mode,model,opt,epoch)\n",
    "                if verbose:\n",
    "                    print_info(mode,loss,t0,epoch)\n",
    "#                 if mode == \"train\":\n",
    "#                     torch.save(model.state_dict(), saved_model_dir +'/epoch_%i.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(nn.Module):\n",
    "    def __init__(self,env=\"CarRacing\"):\n",
    "        super(M,self).__init__()\n",
    "        if env == \"CarRacing\":\n",
    "            self.nz = 32\n",
    "            self.nh = 256\n",
    "            self.action_len = 3 #3 continuous values\n",
    "        elif env == \"Doom\":\n",
    "            pass\n",
    "#             self.nz = 64\n",
    "#             self.nh = 512\n",
    "\n",
    "        self.num_gaussians = 5\n",
    "        \n",
    "        self.sigma_len = self.nz\n",
    "        self.mu_len = self.nz\n",
    "        self.pi_len = 1\n",
    "        self.len_mdp_output = 5*(self.sigma_len + self.mu_len + self.pi_len)\n",
    "        \n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=self.nz+self.action_len,\n",
    "                           hidden_size=self.nh,num_layers=1)\n",
    "        \n",
    "        self.mdn_fc = nn.Linear(in_features=self.nh,\n",
    "                                out_features=self.len_mdp_output)\n",
    "        \n",
    "        self.h_prev = Variable(torch.Tensor(1,batch_size,m.nh).normal_()).cuda()\n",
    "        self.c_prev = Variable(torch.Tensor(1,batch_size,m.nh).normal_()).cuda()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h_prev = Variable(torch.Tensor(1,batch_size,m.nh).normal_()).cuda()\n",
    "        self.c_prev = Variable(torch.Tensor(1,batch_size,m.nh).normal_()).cuda()\n",
    "    \n",
    "    def postproc_mdp_out(self,mdp_out):\n",
    "        mus = mdp_out[:,:self.num_gaussians*self.nz]\n",
    "\n",
    "        sigmas= mdp_out[:,self.num_gaussians*self.nz:2*self.num_gaussians*self.nz]\n",
    "        \n",
    "        pis = mdp_out[:,-self.num_gaussians:]\n",
    "        \n",
    "        \n",
    "        mus = mus.resize(mus.size(0),self.num_gaussians,self.nz)\n",
    "        \n",
    "        sigmas = torch.exp(sigmas)\n",
    "        sigmas = sigmas.resize(sigmas.size(0),self.num_gaussians,self.nz)\n",
    "        \n",
    "        pis = F.softmax(pis,dim=1)\n",
    "        return mus, sigmas, pis\n",
    "                        \n",
    "    \n",
    "    def forward(self, az):\n",
    "        \n",
    "\n",
    "        lstm_out, (self.h_prev,self.c_prev) = self.rnn(az[None,:],(self.h_prev,self.c_prev))\n",
    "        \n",
    "        raw_mdp_out = self.mdn_fc(lstm_out[0])\n",
    "        \n",
    "        mus, sigmas, pis = self.postproc_mdp_out(raw_mdp_out)\n",
    "        return mus, sigmas, pis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "m = M().cuda()\n",
    "\n",
    "seq_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(torch.Tensor(seq_len,batch_size,m.nz).normal_()).cuda()\n",
    "\n",
    "a = Variable(torch.Tensor(seq_len,batch_size,3).normal_()).cuda()\n",
    "\n",
    "az = torch.cat((z,a),dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for azi in az:\n",
    "    msp = m(azi)\n",
    "    outs.append(msp)\n",
    "\n",
    "\n",
    "mus,sigmas,pi = msp\n",
    "\n",
    "def calc_normal_pdf(z,mus,sigmas):\n",
    "    num_mixtures = mus.size(1)\n",
    "    pdfs = []\n",
    "    for i in range(num_mixtures):\n",
    "        zmmu = z[0] - mus[:,0]\n",
    "\n",
    "        zmmu = zmmu[:,:,None]\n",
    "\n",
    "\n",
    "        sigma = sigmas[:,0]\n",
    "\n",
    "\n",
    "        exp_term = -0.5 * zmmu.transpose(2,1) @ (zmmu / sigma[:,:,None])\n",
    "\n",
    "        torch.exp(exp_term[:,0,0])\n",
    "\n",
    "        torch.prod(sigma,dim=1).size()\n",
    "\n",
    "        coeff = (1 / (2*np.pi)) * torch.prod(sigma,dim=1)\n",
    "\n",
    "        pdf = coeff * torch.exp(exp_term[:,0,0])\n",
    "        pdfs.append(pdf[:,None])\n",
    "    return torch.cat(pdfs,dim=1)\n",
    "\n",
    "normals = calc_normal_pdf(z,mus,sigmas)\n",
    "\n",
    "pdf = (pis * normals).sum(dim=1)\n",
    "\n",
    "nll = -torch.log(pdf)\n",
    "\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
