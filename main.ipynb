{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. ~~Code up VAE~~\n",
    "2. ~~Code up M (RNN)~~\n",
    "3. Code up Train Loop for M\n",
    "3. Code up C (Controller)\n",
    "4. Set up Car Racing\n",
    "5. Set up Doom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "import time\n",
    "from torch import optim\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "    sys.argv = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--weights_file\",type=str,default=\"None\")\n",
    "parser.add_argument(\"--lr\",type=float, default=0.0001)\n",
    "parser.add_argument(\"--ctl_type\",type=str, default=\"lstm\")\n",
    "parser.add_argument(\"--opt\",type=str, default=\"adam\")\n",
    "parser.add_argument(\"--iters\",type=int, default=100000)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    display(display_animation(anim, default_mode='loop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(bs=128,nb=1):\n",
    "    for _ in range(nb):\n",
    "        x = Variable(torch.Tensor(bs,3,64,64).uniform_(-1,1)).cuda()\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,env=\"CarRacing\"):\n",
    "        super(VAE,self).__init__()\n",
    "        if env == \"CarRacing\":\n",
    "            nz = 32\n",
    "        elif env == \"Doom\":\n",
    "            nz = 64\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=32,kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4, stride=2),\n",
    "            nn.ReLU())\n",
    "        self.sigma_fc = nn.Linear(in_features=256*2*2,out_features=nz)\n",
    "        self.mu_fc = nn.Linear(in_features=256*2*2,out_features=nz)\n",
    "        \n",
    "        self.decode_fc = nn.Linear(in_features=32,out_features=1024)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=1024,out_channels=128,kernel_size=5,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=5,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=6,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=32,out_channels=3,kernel_size=6,stride=2),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self,x):\n",
    "        vec = self.encoder(x)\n",
    "        \n",
    "        #flatten\n",
    "        vec = vec.view(vec.size(0),-1)\n",
    "        mu, sigma = self.mu_fc(vec), self.sigma_fc(vec)\n",
    "        z = self.reparameterize(mu,sigma)\n",
    "        im = self.decode_fc(z)\n",
    "        \n",
    "        #reshape into im\n",
    "        im = im[:,:,None,None]\n",
    "        \n",
    "        xh = self.decoder(im)\n",
    "        \n",
    "        return xh,mu,sigma\n",
    "        \n",
    "    \n",
    "    def reparameterize(self,mu,sigma):\n",
    "        eps = Variable(torch.Tensor(*sigma.size()).normal_()).cuda()\n",
    "        z = mu + eps*sigma\n",
    "        return z\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x,xh,mu,sigma):\n",
    "    mu_sum_sq = (mu*mu).sum(dim=1)\n",
    "    sig_sum_sq = (sigma*sigma).sum(dim=1)\n",
    "    log_term = (1 + torch.log(sigma**2)).sum(dim=1)\n",
    "    kldiv = 0.5 * (log_term - mu_sum_sq - sig_sum_sq)\n",
    "    \n",
    "    rec = F.mse_loss(xh,x)\n",
    "    \n",
    "    return rec + kldiv.mean()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim(name,  model, lr, momentum):\n",
    "    if name == \"adam\":\n",
    "        return optim.Adam(params=model.parameters(),\n",
    "                        lr=lr)\n",
    "    elif name == \"sgd\":\n",
    "        return optim.SGD(params=model.parameters(),\n",
    "                        lr=lr,\n",
    "                        momentum=momentum)\n",
    "    elif name == \"rmsprop\":\n",
    "          return optim.RMSprop(params=model.parameters(),\n",
    "                        lr=lr,\n",
    "                        momentum=momentum)\n",
    "\n",
    "def print_info(mode,loss,t0,it):\n",
    "    print(\"time: %8.4f\"% (time.time() - t0))\n",
    "    print(\"%s Loss for it %i: %8.4f\"%(mode.capitalize(),it,loss))\n",
    "    #print(\"%s Accuracy for epoch %i: %8.4f\"%(mode.capitalize(),epoch,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(mode, model,opt,epoch):\n",
    "    criterion = vae_loss\n",
    "    dataloader = data_gen()\n",
    "    if mode == \"train\":\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    it_losses = []\n",
    "    for it, xv in enumerate(dataloader):\n",
    "\n",
    "        if mode == \"train\":\n",
    "            opt.zero_grad()\n",
    "        xh,mu,sigma = model(xv)\n",
    "\n",
    "        loss = criterion(xv,xh,mu,sigma)\n",
    "\n",
    "        it_losses.append(loss.data[0])\n",
    "        if mode == \"train\":\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "    loss = np.mean(it_losses)\n",
    "    #writer.add_scalar(\"%s/loss\"%mode,scalar_value=loss,global_step=epoch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "            model,\n",
    "            lr=0.1,\n",
    "            momentum=0.9,\n",
    "            test=False,\n",
    "            val=True,\n",
    "            verbose=True,\n",
    "            num_epochs=5, optimizer=\"adam\"):\n",
    "    \n",
    "        if test:\n",
    "            modes = [\"test\"]\n",
    "            num_epochs = 1\n",
    "            if args.weights_file == \"None\":\n",
    "                assert False, \"I don't think you meant to run on the test set without a weights file!\"\n",
    "        else:\n",
    "            modes = [\"train\"]\n",
    "            if val:\n",
    "                modes.append(\"val\")\n",
    "        \n",
    "        if args.weights_file != \"None\":\n",
    "            model.load_state_dict(torch.load(args.weights_file))\n",
    "\n",
    "\n",
    "        model = model.cuda()\n",
    "        opt = get_optim(optimizer,model,lr,momentum)\n",
    "        for epoch in range(num_epochs):\n",
    "            for mode in modes:\n",
    "                t0 = time.time()\n",
    "                loss = do_epoch(mode,model,opt,epoch)\n",
    "                if verbose:\n",
    "                    print_info(mode,loss,t0,epoch)\n",
    "#                 if mode == \"train\":\n",
    "#                     torch.save(model.state_dict(), saved_model_dir +'/epoch_%i.pt' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = next(data_gen().__iter__())\n",
    "\n",
    "# V = VAE().cuda()\n",
    "\n",
    "# xh,mu,sigma = V(x)\n",
    "\n",
    "# loss = vae_loss(x,xh,mu,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:   4.1645\n",
      "Train Loss for it 0: -41.1274\n",
      "time:   0.1297\n",
      "Val Loss for it 0: -42.6591\n",
      "time:   0.1040\n",
      "Train Loss for it 1: -42.8650\n",
      "time:   0.1204\n",
      "Val Loss for it 1: -44.2696\n",
      "time:   0.0991\n",
      "Train Loss for it 2: -43.7002\n",
      "time:   0.1206\n",
      "Val Loss for it 2: -44.4730\n",
      "time:   0.1000\n",
      "Train Loss for it 3: -44.8610\n",
      "time:   0.1177\n",
      "Val Loss for it 3: -44.9915\n",
      "time:   0.1001\n",
      "Train Loss for it 4: -45.5676\n",
      "time:   0.1203\n",
      "Val Loss for it 4: -46.3006\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    V = VAE()\n",
    "\n",
    "    train(V,lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(nn.Module):\n",
    "    def __init__(self,env=\"CarRacing\"):\n",
    "        super(M,self).__init__()\n",
    "        if env == \"CarRacing\":\n",
    "            self.nz = 32\n",
    "            self.nh = 256\n",
    "            self.action_len = 3 #3 continuous values\n",
    "        elif env == \"Doom\":\n",
    "            pass\n",
    "#             self.nz = 64\n",
    "#             self.nh = 512\n",
    "\n",
    "        self.num_gaussians = 5\n",
    "        \n",
    "        self.sigma_len = self.nz\n",
    "        self.mu_len = self.nz\n",
    "        self.pi_len = 1\n",
    "        self.len_mdp_output = 5*(self.sigma_len + self.mu_len + self.pi_len)\n",
    "        \n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=self.nz+self.action_len,\n",
    "                           hidden_size=self.nh,num_layers=1)\n",
    "        \n",
    "        self.mdn_fc = nn.Linear(in_features=self.nh,\n",
    "                                out_features=self.len_mdp_output)\n",
    "        \n",
    "        self.h_prev = Variable(torch.Tensor(1,batch_size,m.nh).normal_()).cuda()\n",
    "        self.c_prev = Variable(torch.Tensor(1,batch_size,m.nh).normal_()).cuda()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h_prev = Variable(torch.Tensor(1,batch_size,m.nh).normal_()).cuda()\n",
    "        self.c_prev = Variable(torch.Tensor(1,batch_size,m.nh).normal_()).cuda()\n",
    "    \n",
    "    def postproc_mdp_out(self,mdp_out):\n",
    "        mus = mdp_out[:,:self.num_gaussians*self.nz]\n",
    "\n",
    "        sigmas= mdp_out[:,self.num_gaussians*self.nz:2*self.num_gaussians*self.nz]\n",
    "        \n",
    "        pis = mdp_out[:,-self.num_gaussians:]\n",
    "        \n",
    "        \n",
    "        mus = mus.resize(mus.size(0),self.num_gaussians,self.nz)\n",
    "        \n",
    "        sigmas = torch.exp(sigmas)\n",
    "        sigmas = sigmas.resize(sigmas.size(0),self.num_gaussians,self.nz)\n",
    "        \n",
    "        pis = F.softmax(pis,dim=1)\n",
    "        return mus, sigmas, pis\n",
    "                        \n",
    "    \n",
    "    def forward(self, az):\n",
    "        \n",
    "\n",
    "        lstm_out, (self.h_prev,self.c_prev) = self.rnn(az[None,:],(self.h_prev,self.c_prev))\n",
    "        \n",
    "        raw_mdp_out = self.mdn_fc(lstm_out[0])\n",
    "        \n",
    "        mus, sigmas, pis = self.postproc_mdp_out(raw_mdp_out)\n",
    "        return mus, sigmas, pis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "m = M().cuda()\n",
    "\n",
    "seq_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(torch.Tensor(seq_len,batch_size,m.nz).normal_()).cuda()\n",
    "\n",
    "a = Variable(torch.Tensor(seq_len,batch_size,3).normal_()).cuda()\n",
    "\n",
    "az = torch.cat((z,a),dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       "  8.3264e-01 -1.5553e+00  6.7560e-01  ...  -6.4484e-01 -8.5330e-02 -1.5184e+00\n",
       "  9.6795e-01 -6.8876e-01  3.3358e-01  ...   3.8021e-02 -4.4560e-02 -1.6403e-01\n",
       "  3.5661e-01 -1.4102e-01 -5.0923e-01  ...  -1.0018e+00  1.6424e-02 -2.3967e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  7.9887e-01 -2.3134e+00  1.3460e+00  ...   6.8913e-02 -8.7446e-01 -1.6146e+00\n",
       "  1.1519e+00 -3.2552e-01  2.7568e-01  ...   2.3266e+00  9.0345e-01 -2.2876e-01\n",
       " -5.4487e-01 -4.3077e-01  3.7654e-01  ...   7.7189e-02  4.1499e-01  1.6228e+00\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  2.1760e+00 -1.9260e+00  8.6509e-01  ...  -6.1966e-01  5.1640e-01  8.0364e-01\n",
       " -1.5310e+00  5.9219e-01 -4.4613e-01  ...  -9.7488e-01  2.6564e+00 -1.1863e+00\n",
       " -3.9626e-01 -1.8857e+00  4.7410e-01  ...  -5.9115e-01  1.2153e+00 -1.3075e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.1667e+00 -2.1198e-02  7.2850e-01  ...  -1.5191e-01 -6.4944e-01  6.1119e-01\n",
       " -1.2015e-01 -8.2213e-01 -1.3820e+00  ...   4.6804e-02  1.2656e-01  6.0544e-01\n",
       "  8.5980e-01 -4.8073e-01 -1.6942e+00  ...  -1.0099e+00  1.4691e-01 -7.1454e-01\n",
       "\n",
       "( 2 ,.,.) = \n",
       " -8.1645e-02 -1.1122e+00  1.3428e-01  ...  -1.6145e-01 -8.5180e-01  2.5898e-01\n",
       " -4.1257e-01  5.5614e-01  4.0562e-01  ...  -4.0974e-01  9.2076e-01  2.9932e-01\n",
       " -6.7437e-01  6.1719e-01  1.7380e+00  ...  -2.0095e+00  9.0782e-02  4.8250e-01\n",
       "                 ...                   ⋱                   ...                \n",
       " -3.4733e-02 -2.0730e-01  1.0226e+00  ...  -2.7268e-01  1.0033e+00  3.4375e-01\n",
       "  3.4406e-01 -2.3635e-01 -1.9545e-01  ...   9.5650e-01 -3.0062e-01 -7.9186e-01\n",
       "  9.7894e-01 -6.7448e-01 -1.0766e-01  ...   1.8188e-01 -1.2524e-01  1.6897e-03\n",
       "... \n",
       "\n",
       "(17 ,.,.) = \n",
       "  3.4032e-01 -8.4384e-01 -8.0437e-01  ...   7.0386e-01 -5.3634e-01 -7.0325e-01\n",
       " -1.5222e+00 -7.3738e-01 -2.4350e+00  ...   1.6910e+00 -2.4818e+00  1.1534e+00\n",
       " -1.0189e-01 -7.1795e-01  1.2264e+00  ...  -1.6579e-01 -1.5032e+00  1.0750e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.0399e+00 -8.8680e-02  1.7565e+00  ...  -9.1381e-01  3.0446e-02  4.6415e-01\n",
       "  1.4023e+00  1.3314e+00  3.3973e-02  ...   4.5706e-01 -2.5634e-01 -3.7856e-01\n",
       " -1.5610e-01  1.3025e+00 -1.8358e+00  ...   1.4852e-01 -2.0278e-01  8.3562e-01\n",
       "\n",
       "(18 ,.,.) = \n",
       "  1.4267e+00  7.1881e-02  1.1161e+00  ...   1.1212e+00 -6.5968e-01  6.7956e-01\n",
       "  8.5620e-01 -2.4854e+00  1.0086e+00  ...  -1.4809e+00 -1.2174e+00  6.2077e-02\n",
       " -2.8451e-01 -1.0244e+00  2.2818e-01  ...   4.9025e-01  3.3523e-01  7.8020e-01\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.7734e+00  7.8353e-01 -4.4921e-01  ...   1.4824e+00 -5.8125e-01  6.3547e-01\n",
       "  2.1589e+00 -9.9960e-01 -8.8874e-01  ...   6.2078e-01  1.4103e-01 -6.8054e-01\n",
       " -1.1583e+00 -1.1696e+00  1.3641e+00  ...   1.2879e+00  4.1841e-01 -6.0558e-01\n",
       "\n",
       "(19 ,.,.) = \n",
       " -9.5680e-01 -1.1667e+00 -1.0158e-01  ...  -4.7399e-01 -3.2307e-01 -6.8905e-01\n",
       "  4.9591e-01  8.3251e-01 -1.6137e+00  ...   8.4419e-01  2.8546e-01  7.4750e-01\n",
       "  1.3711e+00  2.2874e-01  1.6493e+00  ...  -3.5912e-01  2.2195e+00  3.3153e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -7.9071e-01  1.2843e+00  3.2747e-02  ...   9.8788e-01  8.6356e-01 -1.1512e-01\n",
       " -7.8618e-02 -6.7891e-01  1.6992e+00  ...  -1.0286e-01  1.0878e+00 -1.3144e-01\n",
       " -1.8553e-01  4.5712e-01 -5.3430e-01  ...  -2.8844e-01  1.1287e-01  2.2177e-01\n",
       "[torch.cuda.FloatTensor of size 20x128x35 (GPU 0)]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for azi in az:\n",
    "    msp = m(azi)\n",
    "    outs.append(msp)\n",
    "\n",
    "\n",
    "mus,sigmas,pi = msp\n",
    "\n",
    "def calc_normal_pdf(z,mus,sigmas):\n",
    "    num_mixtures = mus.size(1)\n",
    "    pdfs = []\n",
    "    for i in range(num_mixtures):\n",
    "        zmmu = z[0] - mus[:,0]\n",
    "\n",
    "        zmmu = zmmu[:,:,None]\n",
    "\n",
    "\n",
    "        sigma = sigmas[:,0]\n",
    "\n",
    "\n",
    "        exp_term = -0.5 * zmmu.transpose(2,1) @ (zmmu / sigma[:,:,None])\n",
    "\n",
    "        torch.exp(exp_term[:,0,0])\n",
    "\n",
    "        torch.prod(sigma,dim=1).size()\n",
    "\n",
    "        coeff = (1 / (2*np.pi)) * torch.prod(sigma,dim=1)\n",
    "\n",
    "        pdf = coeff * torch.exp(exp_term[:,0,0])\n",
    "        pdfs.append(pdf[:,None])\n",
    "    return torch.cat(pdfs,dim=1)\n",
    "\n",
    "normals = calc_normal_pdf(z,mus,sigmas)\n",
    "\n",
    "pdf = (pis * normals).sum(dim=1)\n",
    "\n",
    "nll = -torch.log(pdf)\n",
    "\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
