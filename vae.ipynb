{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ~~set up car racing rollout dataloader for VAE~~\n",
    "6. ~~add nice way to save action,z pairs in same dir for VAE~~\n",
    "    ~~* do we save a,z pairs or we just train it up~~\n",
    "7. ~~add in weight init~~\n",
    "5. ~~tensorboardize~~\n",
    "6. ~~add weight saving~~\n",
    "7. add disentangling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Track generation: 1273..1595 -> 322-tiles track\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# setup rendering before importing other stuff (weird hack to avoid pyglet errors)\n",
    "env = gym.make(\"CarRacing-v0\")\n",
    "_ = env.reset()\n",
    "_ = env.render(\"rgb_array\")\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "from torch import optim\n",
    "import os\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "import sys\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose,Normalize,Resize,ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import math\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_notebook = False\n",
    "if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "    sys.argv = [\"\"]\n",
    "    test_notebook= True\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--weights_file\",type=str,default=\"None\")\n",
    "parser.add_argument(\"--lr\",type=float, default=0.001)\n",
    "parser.add_argument(\"--opt\",type=str, default=\"adam\")\n",
    "parser.add_argument(\"--rollouts\",type=int, default=4)\n",
    "parser.add_argument(\"--batch_size\",type=int, default=128)\n",
    "parser.add_argument(\"--savedir\",type=str, default=\"/data/milatmp1/racaheva\")\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_action = 3\n",
    "rollout_len = 1000\n",
    "basename=\"vae\"\n",
    "def mkstr(key):\n",
    "    d = args.__dict__\n",
    "    return \"=\".join([key,str(d[key])])\n",
    "\n",
    "output_dirname = \"_\".join([basename,mkstr(\"lr\"),mkstr(\"rollouts\"),mkstr(\"batch_size\"),mkstr(\"opt\")])\n",
    "\n",
    "if test_notebook:\n",
    "    output_dirname = \"notebook_\" + output_dirname\n",
    "saved_model_dir = os.path.join(args.savedir,(\"models/%s\" % output_dirname))\n",
    "log_dir = os.path.join(args.savedir,('.logs/%s'%output_dirname))\n",
    "az_pair_dir = os.path.join(args.savedir,(\"az_pairs/%s\" % output_dirname))\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "if not os.path.exists(az_pair_dir):\n",
    "    os.makedirs(az_pair_dir)\n",
    "\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "#####\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    display(display_animation(anim, default_mode='loop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    \"\"\"Dataset from a single rollout\"\"\"\n",
    "\n",
    "    def __init__(self, data,transform=None):\n",
    "        self.data = data\n",
    "        # get between -1 and 1\n",
    "#         self.data = ((data / 255) - 0.5 ) * 2\n",
    "#         self.data = self.data.transpose(0,3,1,2)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rollout(env_name=\"CarRacing-v0\"):\n",
    "    env = gym.make(env_name)\n",
    "    frames = []\n",
    "    actions = []\n",
    "    state = env.reset()\n",
    "    frame = Image.fromarray(state, 'RGB')\n",
    "    frames.append(frame)\n",
    "    s = env.render(\"rgb_array\")\n",
    "    done=False\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        state,r,done,_ = env.step(action)\n",
    "        frame = Image.fromarray(state, 'RGB')\n",
    "        frames.append(frame)\n",
    "        actions.append(action[None,:])\n",
    "    actions = np.concatenate(actions)\n",
    "#     frames = np.concatenate(frames)\n",
    "    return frames,actions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frame_iterator(frames,batch_size=128,env_name=\"CarRacing-v0\"):\n",
    "    # b/c we use sigmoid\n",
    "    transforms = Compose([Resize((64,64)),ToTensor()])#,Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])\n",
    "    rds = FrameDataset(frames,transform=transforms)\n",
    "\n",
    "\n",
    "    frame_iter = DataLoader(rds,batch_size=batch_size)\n",
    "    return frame_iter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim(name,  model, lr, momentum=0.):\n",
    "    if name == \"adam\":\n",
    "        return optim.Adam(params=model.parameters(),\n",
    "                        lr=lr)\n",
    "    elif name == \"sgd\":\n",
    "        return optim.SGD(params=model.parameters(),\n",
    "                        lr=lr,\n",
    "                        momentum=momentum)\n",
    "    elif name == \"rmsprop\":\n",
    "          return optim.RMSprop(params=model.parameters(),\n",
    "                        lr=lr,\n",
    "                        momentum=momentum)\n",
    "\n",
    "def print_info(mode,loss,t0,it):\n",
    "    print(\"time: %8.4f\"% (time.time() - t0))\n",
    "    print(\"%s Loss for it %i: %8.4f\"%(mode.capitalize(),it,loss))\n",
    "    #print(\"%s Accuracy for epoch %i: %8.4f\"%(mode.capitalize(),epoch,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,env=\"CarRacing\"):\n",
    "        super(VAE,self).__init__()\n",
    "        if env == \"CarRacing\":\n",
    "            self.nz = 32\n",
    "        elif env == \"Doom\":\n",
    "            self.nz = 64\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=32,kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4, stride=2),\n",
    "            nn.ReLU())\n",
    "        self.sigma_fc = nn.Linear(in_features=256*2*2,out_features=self.nz)\n",
    "        self.mu_fc = nn.Linear(in_features=256*2*2,out_features=self.nz)\n",
    "        \n",
    "        self.decode_fc = nn.Linear(in_features=32,out_features=1024)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=1024,out_channels=128,kernel_size=5,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=5,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=6,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=32,out_channels=3,kernel_size=6,stride=2),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self,x):\n",
    "        vec = self.encoder(x)\n",
    "        \n",
    "        #flatten\n",
    "        vec = vec.view(vec.size(0),-1)\n",
    "        mu, sigma = self.mu_fc(vec), self.sigma_fc(vec)\n",
    "        z = self.reparameterize(mu,sigma)\n",
    "        im = self.decode_fc(z)\n",
    "        \n",
    "        #reshape into im\n",
    "        im = im[:,:,None,None]\n",
    "        \n",
    "        xr = self.decoder(im)\n",
    "        \n",
    "        return xr,mu,sigma,z\n",
    "        \n",
    "    \n",
    "    def reparameterize(self,mu,sigma):\n",
    "        eps = Variable(torch.Tensor(*sigma.size()).normal_()).cuda()\n",
    "        z = mu + eps*sigma\n",
    "        return z\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "\n",
    "def vae_loss(x,xr,mu,sigma):\n",
    "    mu_sum_sq = (mu*mu).sum(dim=1)\n",
    "    sig_sum_sq = (sigma*sigma).sum(dim=1)\n",
    "    log_term = (1 + torch.log(sigma**2)).sum(dim=1)\n",
    "    kldiv = -0.5 * (log_term - mu_sum_sq - sig_sum_sq)\n",
    "    \n",
    "    rec = F.mse_loss(xr,x)\n",
    "    \n",
    "    return rec + kldiv.mean()\n",
    "    \n",
    "# def loss_function(recon_x, x, mu, logvar):\n",
    "#     BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), size_average=False)\n",
    "\n",
    "#     # see Appendix B from VAE paper:\n",
    "#     # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "#     # https://arxiv.org/abs/1312.6114\n",
    "#     # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "#     KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "#     return BCE + KLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Track generation: 1331..1668 -> 337-tiles track\n",
      "33.0722501278\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Track generation: 1208..1514 -> 306-tiles track\n",
      "7.72608014941\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Track generation: 1215..1523 -> 308-tiles track\n",
      "1.73508463055\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Track generation: 1071..1343 -> 272-tiles track\n",
      "0.668504852802\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    V = VAE().cuda()\n",
    "    all_actions = np.zeros((args.rollouts,rollout_len+1,len_action))\n",
    "    all_z = np.zeros((args.rollouts,rollout_len+1,V.nz))\n",
    "    az_fn = os.path.join(az_pair_dir,\"az.npz\")\n",
    "\n",
    "    opt = get_optim(name=args.opt,lr=args.lr,model=V)\n",
    "    criterion = vae_loss\n",
    "    for epoch in range(args.rollouts):\n",
    "        frames,actions = generate_rollout()\n",
    "        actions = all_actions[epoch,:rollout_len] = actions\n",
    "        dataloader = make_frame_iterator(frames)\n",
    "        V.train()\n",
    "        it_losses = []\n",
    "        zs = []\n",
    "        opt.zero_grad()\n",
    "        for it, x in enumerate(dataloader):\n",
    "            xv = Variable(x).float().cuda()\n",
    "            xr,mu,sigma,z = V(xv)\n",
    "\n",
    "            rows = 6 #int(math.sqrt(args.batch_size))\n",
    "            num_ims = rows**2\n",
    "            xr_grid = make_grid(xr.data[:num_ims], rows)\n",
    "            writer.add_image(\"x_rec\", xr_grid, epoch)\n",
    "            x_grid = make_grid(xv.data[:num_ims],rows)\n",
    "            writer.add_image(\"x_orig\", x_grid, epoch)\n",
    "            zs.append(z)\n",
    "            loss = criterion(xv,xr,mu,sigma)\n",
    "            it_losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        loss = np.mean(it_losses)\n",
    "        print(loss)\n",
    "        zs = torch.cat(zs)\n",
    "        all_z[epoch,:,:] = zs\n",
    "        #az = zip(torch.from_numpy(actions),zs)\n",
    "        writer.add_scalar(\"loss\",scalar_value=loss,global_step=epoch)\n",
    "        torch.save(V.state_dict(), '%s/currVAE.pth' % (saved_model_dir))\n",
    "        if epoch % 100 == 0:\n",
    "            np.savez(az_fn,a=all_actions,z=all_z)\n",
    "            torch.save(V.state_dict(), '%s/currVAE_%s.pth' % (saved_model_dir,epoch))\n",
    "    np.savez(az_fn,a=all_actions,z=all_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
